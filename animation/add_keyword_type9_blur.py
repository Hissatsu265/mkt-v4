from moviepy.editor import VideoFileClip, CompositeVideoClip, concatenate_videoclips
import numpy as np
from scipy.ndimage import gaussian_filter
from PIL import Image, ImageDraw, ImageFont
import cv2

def apply_blur(image):
    """Ãp dá»¥ng gaussian blur cho frame"""
    blurred = np.stack([
        gaussian_filter(image[:,:,i], sigma=10)
        for i in range(3)
    ], axis=2)
    # Giáº£m Ä‘á»™ sÃ¡ng Ä‘á»ƒ lÃ m ná»n
    return (blurred * 0.5).astype('uint8')


def get_optimal_font_size(width, height, font_path=None):
    """
    Tá»± Ä‘á»™ng tÃ­nh toÃ¡n font size phÃ¹ há»£p dá»±a trÃªn kÃ­ch thÆ°á»›c video

    Returns:
    - font_size: kÃ­ch thÆ°á»›c font phÃ¹ há»£p
    """
    # XÃ¡c Ä‘á»‹nh orientation
    if width > height:  # Landscape 16:9
        # Font size dá»±a trÃªn chiá»u cao (khoáº£ng 8-10% chiá»u cao)
        font_size = int(height * 0.12)
    else:  # Portrait 9:16
        # Font size dá»±a trÃªn chiá»u rá»™ng (khoáº£ng 12-15% chiá»u rá»™ng)
        font_size = int(width * 0.15)

    return font_size


def wrap_text(text, font, max_width, draw):
    """
    Tá»± Ä‘á»™ng xuá»‘ng hÃ ng cho text náº¿u quÃ¡ dÃ i

    Parameters:
    - text: ná»™i dung text
    - font: font object
    - max_width: chiá»u rá»™ng tá»‘i Ä‘a cho phÃ©p
    - draw: ImageDraw object Ä‘á»ƒ tÃ­nh toÃ¡n kÃ­ch thÆ°á»›c

    Returns:
    - lines: list cÃ¡c dÃ²ng text sau khi wrap
    """
    words = text.split(' ')
    lines = []
    current_line = []

    for word in words:
        # Thá»­ thÃªm tá»« vÃ o dÃ²ng hiá»‡n táº¡i
        test_line = ' '.join(current_line + [word])
        bbox = draw.textbbox((0, 0), test_line, font=font)
        test_width = bbox[2] - bbox[0]

        if test_width <= max_width:
            current_line.append(word)
        else:
            # Náº¿u dÃ²ng hiá»‡n táº¡i khÃ´ng rá»—ng, lÆ°u láº¡i vÃ  báº¯t Ä‘áº§u dÃ²ng má»›i
            if current_line:
                lines.append(' '.join(current_line))
                current_line = [word]
            else:
                # TrÆ°á»ng há»£p tá»« Ä‘Æ¡n láº» quÃ¡ dÃ i, váº«n pháº£i thÃªm vÃ o
                lines.append(word)
                current_line = []

    # ThÃªm dÃ²ng cuá»‘i cÃ¹ng
    if current_line:
        lines.append(' '.join(current_line))

    return lines


def create_text_clip(text, duration, size, start_time, font_path=None):
    """
    Táº¡o clip text báº±ng PIL vá»›i font size tá»± Ä‘á»™ng Ä‘iá»u chá»‰nh vÃ  auto wrap

    Parameters:
    - text: ná»™i dung text
    - duration: thá»i lÆ°á»£ng hiá»ƒn thá»‹
    - size: (width, height) cá»§a video
    - start_time: thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u
    - font_path: Ä‘Æ°á»ng dáº«n Ä‘áº¿n file .ttf (náº¿u None sáº½ dÃ¹ng font máº·c Ä‘á»‹nh)
    """
    width, height = size

    # TÃ­nh toÃ¡n font size phÃ¹ há»£p
    font_size = get_optimal_font_size(width, height)

    # TÃ­nh stroke width dá»±a trÃªn font size
    stroke_width = max(3, int(font_size * 0.06))

    # TÃ­nh max width cho text (90% chiá»u rá»™ng video Ä‘á»ƒ cÃ³ padding)
    max_text_width = int(width * 0.9)

    def make_frame(t):
        # Táº¡o frame trong suá»‘t vá»›i 3 channels (RGB)
        img = Image.new('RGB', (width, height), (0, 0, 0))
        draw = ImageDraw.Draw(img)

        # Táº£i font
        try:
            if font_path:
                font = ImageFont.truetype(font_path, font_size)
            else:
                # Thá»­ cÃ¡c font máº·c Ä‘á»‹nh
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
        except:
            try:
                font = ImageFont.truetype("arial.ttf", font_size)
            except:
                font = ImageFont.load_default()

        # Wrap text náº¿u cáº§n
        lines = wrap_text(text, font, max_text_width, draw)

        # TÃ­nh toÃ¡n kÃ­ch thÆ°á»›c tá»•ng cá»§a text block (nhiá»u dÃ²ng)
        line_heights = []
        line_widths = []
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            line_widths.append(bbox[2] - bbox[0])
            line_heights.append(bbox[3] - bbox[1])

        # TÃ­nh line spacing (khoáº£ng cÃ¡ch giá»¯a cÃ¡c dÃ²ng)
        line_spacing = int(font_size * 0.2)

        # Tá»•ng chiá»u cao cá»§a text block
        total_height = sum(line_heights) + line_spacing * (len(lines) - 1)

        # Vá»‹ trÃ­ báº¯t Ä‘áº§u y (cÄƒn giá»¯a theo chiá»u dá»c)
        start_y = (height - total_height) // 2

        # Váº½ tá»«ng dÃ²ng
        current_y = start_y
        for i, line in enumerate(lines):
            # TÃ­nh vá»‹ trÃ­ x Ä‘á»ƒ cÄƒn giá»¯a dÃ²ng nÃ y
            x = (width - line_widths[i]) // 2
            y = current_y

            # Váº½ viá»n Ä‘en (stroke)
            for adj_x in range(-stroke_width, stroke_width+1):
                for adj_y in range(-stroke_width, stroke_width+1):
                    draw.text((x+adj_x, y+adj_y), line, font=font, fill=(0, 0, 0))

            # Váº½ text tráº¯ng
            draw.text((x, y), line, font=font, fill=(255, 255, 255))

            # Di chuyá»ƒn Ä‘áº¿n dÃ²ng tiáº¿p theo
            current_y += line_heights[i] + line_spacing

        # Convert sang numpy array RGB
        return np.array(img)

    def make_mask(t):
        # Táº¡o alpha mask - chá»‰ text cÃ³ mÃ u tráº¯ng, pháº§n cÃ²n láº¡i Ä‘en
        img = Image.new('L', (width, height), 0)  # L = grayscale
        draw = ImageDraw.Draw(img)

        try:
            if font_path:
                font = ImageFont.truetype(font_path, font_size)
            else:
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
        except:
            try:
                font = ImageFont.truetype("arial.ttf", font_size)
            except:
                font = ImageFont.load_default()

        # Wrap text
        lines = wrap_text(text, font, max_text_width, draw)

        # TÃ­nh toÃ¡n layout
        line_heights = []
        line_widths = []
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            line_widths.append(bbox[2] - bbox[0])
            line_heights.append(bbox[3] - bbox[1])

        line_spacing = int(font_size * 0.2)
        total_height = sum(line_heights) + line_spacing * (len(lines) - 1)
        start_y = (height - total_height) // 2

        # Váº½ tá»«ng dÃ²ng
        current_y = start_y
        for i, line in enumerate(lines):
            x = (width - line_widths[i]) // 2
            y = current_y

            # Váº½ viá»n
            for adj_x in range(-stroke_width, stroke_width+1):
                for adj_y in range(-stroke_width, stroke_width+1):
                    draw.text((x+adj_x, y+adj_y), line, font=font, fill=255)

            # Váº½ text
            draw.text((x, y), line, font=font, fill=255)

            current_y += line_heights[i] + line_spacing

        return np.array(img) / 255.0  # Normalize 0-1

    from moviepy.editor import VideoClip
    text_clip = VideoClip(make_frame, duration=duration)
    text_clip = text_clip.set_start(start_time)
    text_clip = text_clip.set_mask(VideoClip(make_mask, duration=duration, ismask=True))

    return text_clip


def create_keyword_videoblur(video_path, keywords, start_times, end_times, output_path="output_video.mp4", font_path=None):
    """
    Táº¡o video vá»›i hiá»‡u á»©ng blur vÃ  hiá»ƒn thá»‹ keyword

    Parameters:
    - video_path: Ä‘Æ°á»ng dáº«n Ä‘áº¿n video gá»‘c
    - keywords: list cÃ¡c tá»« khÃ³a cáº§n hiá»ƒn thá»‹
    - start_times: list thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u hiá»ƒn thá»‹ (giÃ¢y)
    - end_times: list thá»i Ä‘iá»ƒm káº¿t thÃºc hiá»ƒn thá»‹ (giÃ¢y)
    - output_path: Ä‘Æ°á»ng dáº«n lÆ°u video output
    - font_path: Ä‘Æ°á»ng dáº«n Ä‘áº¿n file font .ttf (None = dÃ¹ng font máº·c Ä‘á»‹nh)
    """

    print("Äang load video...")
    video = VideoFileClip(video_path)
    w, h = video.size

    # Hiá»ƒn thá»‹ thÃ´ng tin video
    print(f"ğŸ“ KÃ­ch thÆ°á»›c video: {w}x{h}")
    if w > h:
        print("ğŸ“º Orientation: Landscape (16:9)")
        font_size = get_optimal_font_size(w, h)
        print(f"âœï¸  Font size: {font_size}px")
    else:
        print("ğŸ“± Orientation: Portrait (9:16)")
        font_size = get_optimal_font_size(w, h)
        print(f"âœï¸  Font size: {font_size}px")

    if font_path:
        print(f"ğŸ”¤ Font: {font_path}")
    else:
        print("ğŸ”¤ Font: System default (DejaVuSans-Bold)")

    # Táº¡o danh sÃ¡ch cÃ¡c khoáº£ng thá»i gian cáº§n blur
    blur_times = []

    for i in range(len(start_times)):
        start = start_times[i]
        end = end_times[i]

        blur_start = start - 0.5

        # Kiá»ƒm tra xem cÃ³ keyword tiáº¿p theo khÃ´ng
        if i < len(start_times) - 1:
            next_start = start_times[i + 1]
            gap = next_start - end

            # Náº¿u khoáº£ng cÃ¡ch < 1s, giá»¯ blur Ä‘áº¿n keyword tiáº¿p theo
            if gap < 1:
                blur_end = next_start - 0.5
            else:
                # Náº¿u khoáº£ng cÃ¡ch > 2s, fade out blur
                blur_end = end
        else:
            blur_end = end

        blur_times.append((blur_start, blur_end))

    # Há»£p nháº¥t cÃ¡c segment blur chá»“ng chÃ©o
    merged_blur_times = merge_segments(blur_times)

    print("Äang táº¡o hiá»‡u á»©ng blur Ä‘á»™ng...")

    # Táº¡o function Ä‘á»ƒ Ã¡p dá»¥ng blur cÃ³ Ä‘iá»u kiá»‡n theo thá»i gian
    def apply_conditional_blur(get_frame, t):
        frame = get_frame(t)

        # Kiá»ƒm tra xem thá»i Ä‘iá»ƒm t cÃ³ náº±m trong khoáº£ng blur khÃ´ng
        should_blur = False
        fade_in = False
        fade_out = False

        for blur_start, blur_end in merged_blur_times:
            if blur_start <= t <= blur_end:
                should_blur = True

                # Kiá»ƒm tra fade in (0.5s Ä‘áº§u)
                if t - blur_start < 0.5:
                    fade_in = True
                    fade_factor = (t - blur_start) / 0.5

                # Kiá»ƒm tra fade out (0.5s cuá»‘i) - chá»‰ khi khÃ´ng cÃ³ keyword tiáº¿p theo gáº§n
                # TÃ¬m keyword tiáº¿p theo
                has_next_nearby = False
                for next_blur_start, _ in merged_blur_times:
                    if next_blur_start > blur_end and next_blur_start - blur_end < 2:
                        has_next_nearby = True
                        break

                if not has_next_nearby and blur_end - t < 0.5:
                    fade_out = True
                    fade_factor = (blur_end - t) / 0.5

                break

        if should_blur:
            # Ãp dá»¥ng blur
            blurred = np.stack([
                gaussian_filter(frame[:,:,i], sigma=10)
                for i in range(3)
            ], axis=2)
            blurred = (blurred * 0.5).astype('uint8')

            # Ãp dá»¥ng fade náº¿u cáº§n
            if fade_in:
                frame = (frame * (1 - fade_factor) + blurred * fade_factor).astype('uint8')
            elif fade_out:
                frame = (blurred * fade_factor + frame * (1 - fade_factor)).astype('uint8')
            else:
                frame = blurred

        return frame

    print("Äang Ã¡p dá»¥ng blur...")
    # Ãp dá»¥ng blur cÃ³ Ä‘iá»u kiá»‡n cho toÃ n bá»™ video
    final_video = video.fl(apply_conditional_blur)

    print("Äang thÃªm text...")
    # ThÃªm text keywords
    text_clips = []
    for i, keyword in enumerate(keywords):
        duration = end_times[i] - start_times[i]
        txt_clip = create_text_clip(keyword, duration, (w, h), start_times[i], font_path)
        text_clips.append(txt_clip)

    # Composite video vá»›i text
    final_with_text = CompositeVideoClip([final_video] + text_clips)

    print("Äang export video...")
    # Export
    final_with_text.write_videofile(
        output_path,
        codec='libx264',
        audio_codec='aac',
        fps=video.fps
    )

    # ÄÃ³ng cÃ¡c clip
    video.close()
    final_with_text.close()

    print(f"âœ… Video Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡i: {output_path}")


def merge_segments(segments):
    """Há»£p nháº¥t cÃ¡c segment thá»i gian chá»“ng chÃ©o"""
    if not segments:
        return []

    # Sáº¯p xáº¿p theo thá»i gian báº¯t Ä‘áº§u
    sorted_segments = sorted(segments, key=lambda x: x[0])
    merged = [sorted_segments[0]]

    for current in sorted_segments[1:]:
        last = merged[-1]
        # Náº¿u overlap hoáº·c gáº§n nhau (< 1s)
        if current[0] <= last[1] + 1:
            # Há»£p nháº¥t
            merged[-1] = (last[0], max(last[1], current[1]))
        else:
            merged.append(current)

    return merged


# if __name__ == "__main__":
#     # ThÃ´ng tin input
#     video_path = "/content/vid1.mp4"  # ÄÆ°á»ng dáº«n video cá»§a báº¡n

#     # ÄÆ°á»ng dáº«n font (Ä‘á»ƒ None náº¿u dÃ¹ng font máº·c Ä‘á»‹nh)
#     # VÃ­ dá»¥: font_path = "/path/to/your/font.ttf"
#     font_path = "/content/WixMadeforDisplay-VariableFont_wght.ttf"

#     # Danh sÃ¡ch keywords vÃ  thá»i gian
#     keywords = [
#         # "Keyworrwerwerw ewrwer",
#         # "Keyword 2",
#     ]

#     start_times = []  # Thá»i Ä‘iá»ƒm báº¯t Ä‘áº§u (giÃ¢y)
#     end_times = []   # Thá»i Ä‘iá»ƒm káº¿t thÃºc (giÃ¢y)

#     # Táº¡o video
#     create_keyword_video(
#         video_path=video_path,
#         keywords=keywords,
#         start_times=start_times,
#         end_times=end_times,
#         output_path="output_video1.mp4",
#         font_path=font_path  # ThÃªm parameter font_path
#     )