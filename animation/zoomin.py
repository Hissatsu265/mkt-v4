import cv2
import numpy as np
from PIL import Image
import os
import mediapipe as mp
import random
import math
import time
from moviepy.editor import VideoFileClip


def wait_for_file_ready(file_path, min_size_mb=0.1, max_wait_time=60, check_interval=1):
    """
    Check if the file is ready for use.
    
    Args:
        file_path: Path to the file.
        min_size_mb: Minimum file size (MB).
        max_wait_time: Maximum wait time (seconds).
        check_interval: Interval between checks (seconds).
    
    Returns:
        bool: True if the file is ready, False if timed out.
    """
    print(f"Checking file readiness: {file_path}")
    start_time = time.time()
    min_size_bytes = min_size_mb * 1024 * 1024
    last_size = 0
    stable_count = 0

    while time.time() - start_time < max_wait_time:
        if not os.path.exists(file_path):
            print(f"File does not exist yet. Waiting {check_interval}s...")
            time.sleep(check_interval)
            continue

        try:
            current_size = os.path.getsize(file_path)
            print(f"Current file size: {current_size / (1024 * 1024):.2f} MB")

            if current_size < min_size_bytes:
                print(f"File not large enough yet ({min_size_mb} MB minimum). Waiting...")
                time.sleep(check_interval)
                continue

            if current_size == last_size:
                stable_count += 1
                if stable_count >= 3:
                    print("âœ… File size is stable, verifying integrity...")

                    try:
                        cap = cv2.VideoCapture(file_path)
                        if cap.isOpened():
                            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                            fps = cap.get(cv2.CAP_PROP_FPS)
                            cap.release()

                            if frame_count > 0 and fps > 0:
                                print(f"âœ… Valid video file - Frames: {frame_count}, FPS: {fps}")
                                return True
                            else:
                                print("âŒ Invalid video file (no frames or FPS)")
                        else:
                            print("âŒ Unable to open video file")
                    except Exception as e:
                        print(f"âŒ Error while verifying file: {e}")

                    time.sleep(check_interval)
            else:
                stable_count = 0
                last_size = current_size
                print("File size still changing...")
                time.sleep(check_interval)

        except Exception as e:
            print(f"Error while checking file: {e}")
            time.sleep(check_interval)

    print(f"âŒ Timeout after {max_wait_time}s")
    return False


def safe_video_processing(input_file, output_file, processing_func, *args, **kwargs):
    """
    Safely process a video with file readiness checks.
    
    Args:
        input_file: Input video file.
        output_file: Output video file.
        processing_func: Video processing function.
        *args, **kwargs: Parameters for the processing function.
    
    Returns:
        bool: True if successful, False otherwise.
    """
    print(f"ðŸ”„ Starting processing: {input_file} -> {output_file}")

    if not wait_for_file_ready(input_file):
        print(f"âŒ Input file not ready: {input_file}")
        return False

    if os.path.exists(output_file):
        try:
            os.remove(output_file)
            print(f"ðŸ—‘ï¸ Old output file removed: {output_file}")
        except Exception as e:
            print(f"âš ï¸ Unable to remove old output file: {e}")

    try:
        result = processing_func(*args, **kwargs)

        if wait_for_file_ready(output_file, min_size_mb=0.5):
            print(f"âœ… Successfully processed: {output_file}")
            return True
        else:
            print(f"âŒ Output file not created properly: {output_file}")
            return False

    except Exception as e:
        print(f"âŒ Error during processing: {e}")
        return False


def safe_create_face_zoom_video(input_video, output_video, **kwargs):
    """
    Safe wrapper for create_face_zoom_video.
    """
    return safe_video_processing(
        input_video,
        output_video,
        create_face_zoom_video,
        input_video=input_video,
        output_video=output_video,
        **kwargs
    )


class VideoFaceZoom:
    def __init__(self, input_video_path, output_video_path):
        self.input_path = input_video_path
        self.output_path = output_video_path

        self.mp_face_detection = mp.solutions.face_detection
        self.mp_drawing = mp.solutions.drawing_utils
        self.face_detection = self.mp_face_detection.FaceDetection(
            model_selection=0, min_detection_confidence=0.5
        )

        self.cap = cv2.VideoCapture(input_video_path)
        if not self.cap.isOpened():
            raise ValueError(f"Cannot open video: {input_video_path}")

        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))
        self.width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.total_frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        self.out = cv2.VideoWriter(output_video_path, fourcc, self.fps, (self.width, self.height))

        if not self.out.isOpened():
            self.cap.release()
            raise ValueError(f"Cannot create video writer: {output_video_path}")

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()

    def release(self):
        """Release all resources"""
        if hasattr(self, 'cap') and self.cap.isOpened():
            self.cap.release()
        if hasattr(self, 'out') and self.out.isOpened():
            self.out.release()
        print(f"âœ… Resources released for: {self.output_path}")

    # Face detection & zoom logic unchanged
    def detect_faces(self, frame):
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = self.face_detection.process(rgb_frame)

        faces = []
        if results.detections:
            for detection in results.detections:
                bbox = detection.location_data.relative_bounding_box

                x = int(bbox.xmin * self.width)
                y = int(bbox.ymin * self.height)
                w = int(bbox.width * self.width)
                h = int(bbox.height * self.height)
                padding_left = 0.3
                padding_right = 0.3
                padding_top = 0.5
                padding_bottom = 0.2
                if self.height > self.width:
                    padding_left = padding_right = padding_top = padding_bottom = 0.1

                x_expand_left = int(w * padding_left)
                x_expand_right = int(w * padding_right)
                y_expand_top = int(h * padding_top)
                y_expand_bottom = int(h * padding_bottom)

                x = max(0, x - x_expand_left)
                y = max(0, y - y_expand_top)
                w = min(self.width - x, w + x_expand_left + x_expand_right)
                h = min(self.height - y, h + y_expand_top + y_expand_bottom)

                faces.append((x, y, x + w, y + h))

        return faces

    def get_largest_face(self, faces):
        if not faces:
            return None
        return max(faces, key=lambda face: (face[2] - face[0]) * (face[3] - face[1]))

    def calculate_zoom_region(self, face_bbox, zoom_factor=1.5):
        x1, y1, x2, y2 = face_bbox
        face_center_x = (x1 + x2) // 2
        face_center_y = (y1 + y2) // 2

        zoom_width = int(self.width / zoom_factor)
        zoom_height = int(self.height / zoom_factor)

        if self.height > self.width:
            face_center_y += int(0.1 * self.height)

        zoom_x1 = max(0, face_center_x - zoom_width // 2)
        zoom_y1 = max(0, face_center_y - zoom_height // 2)
        zoom_x2 = min(self.width, zoom_x1 + zoom_width)
        zoom_y2 = min(self.height, zoom_y1 + zoom_height)

        if zoom_x2 - zoom_x1 < zoom_width:
            zoom_x1 = max(0, zoom_x2 - zoom_width)
        if zoom_y2 - zoom_y1 < zoom_height:
            zoom_y1 = max(0, zoom_y2 - zoom_height)

        return (zoom_x1, zoom_y1, zoom_x2, zoom_y2)

    def smooth_transition(self, current_region, target_region, alpha=0.1):
        if current_region is None:
            return target_region

        smooth_region = [
            int(current_region[i] * (1 - alpha) + target_region[i] * alpha)
            for i in range(4)
        ]
        return tuple(smooth_region)

    def apply_shake_effect(self, zoom_region, shake_intensity=5):
        if zoom_region is None:
            return zoom_region
        x1, y1, x2, y2 = zoom_region
        shake_x = random.randint(-shake_intensity, shake_intensity)
        shake_y = random.randint(-shake_intensity, shake_intensity)
        new_x1 = max(0, min(self.width - (x2 - x1), x1 + shake_x))
        new_y1 = max(0, min(self.height - (y2 - y1), y1 + shake_y))
        new_x2 = new_x1 + (x2 - x1)
        new_y2 = new_y1 + (y2 - y1)
        return (new_x1, new_y1, new_x2, new_y2)

    def calculate_gradual_zoom_factor(self, current_frame, start_frame, end_frame, start_zoom=1.0, end_zoom=1.5):
        if current_frame < start_frame:
            return start_zoom
        elif current_frame >= end_frame:
            return end_zoom
        progress = (current_frame - start_frame) / (end_frame - start_frame)
        eased_progress = 1 - math.cos(progress * math.pi / 2)
        return start_zoom + (end_zoom - start_zoom) * eased_progress

    def apply_zoom_effect(self, frame, zoom_region, zoom_factor=1.5):
        x1, y1, x2, y2 = zoom_region
        cropped = frame[y1:y2, x1:x2]
        zoomed = cv2.resize(cropped, (self.width, self.height), interpolation=cv2.INTER_CUBIC)
        return zoomed

    def process_video(self, zoom_start_frame=None, zoom_duration_frames=None, zoom_factor=1.5, 
                     zoom_type="instant", gradual_start_frame=None, gradual_end_frame=None, 
                     gradual_hold_frames=None, enable_shake=False, shake_intensity=3, shake_start_delay=0.5):

        frame_count = 0
        zoom_region = None
        target_face = None
        shake_start_frame = None
        shake_end_frame = None
        shake_duration_frames = int(0.5 * self.fps)

        if zoom_type == "instant":
            print(f"Instant zoom from frame {zoom_start_frame} to {zoom_start_frame + zoom_duration_frames}")
            if enable_shake:
                shake_start_frame = zoom_start_frame + int(shake_start_delay * self.fps)
                shake_end_frame = shake_start_frame + shake_duration_frames
                print(f"Shake effect from frame {shake_start_frame} to {shake_end_frame}")
        else:
            gradual_total_end = gradual_end_frame + (gradual_hold_frames or 0)
            print(f"Gradual zoom from frame {gradual_start_frame} to {gradual_end_frame}")
            print(f"Holding zoom until frame {gradual_total_end}")
            if enable_shake:
                shake_start_frame = gradual_end_frame + int(shake_start_delay * self.fps)
                shake_end_frame = shake_start_frame + shake_duration_frames
                print(f"Shake effect from frame {shake_start_frame} to {shake_end_frame}")

        try:
            while True:
                ret, frame = self.cap.read()
                if not ret:
                    break

                faces = self.detect_faces(frame)
                current_zoom_factor = 1.0
                should_zoom = False

                if zoom_type == "instant":
                    if zoom_start_frame <= frame_count < zoom_start_frame + zoom_duration_frames:
                        should_zoom = True
                        current_zoom_factor = zoom_factor
                elif zoom_type == "gradual":
                    if gradual_start_frame <= frame_count <= gradual_end_frame:
                        should_zoom = True
                        current_zoom_factor = self.calculate_gradual_zoom_factor(
                            frame_count, gradual_start_frame, gradual_end_frame, 1.0, zoom_factor
                        )
                    elif gradual_hold_frames and gradual_end_frame < frame_count <= gradual_end_frame + gradual_hold_frames:
                        should_zoom = True
                        current_zoom_factor = zoom_factor

                if should_zoom and current_zoom_factor > 1.0:
                    if faces:
                        current_largest = self.get_largest_face(faces)
                        if target_face is None:
                            target_face = current_largest
                        else:
                            target_area = (target_face[2] - target_face[0]) * (target_face[3] - target_face[1])
                            current_area = (current_largest[2] - current_largest[0]) * (current_largest[3] - current_largest[1])
                            if current_area > target_area * 1.2:
                                target_face = current_largest

                        target_zoom_region = self.calculate_zoom_region(target_face, current_zoom_factor)
                        zoom_region = self.smooth_transition(zoom_region, target_zoom_region, alpha=0.15)

                        if (enable_shake and shake_start_frame and shake_end_frame and 
                            shake_start_frame <= frame_count < shake_end_frame):
                            zoom_region = self.apply_shake_effect(zoom_region, shake_intensity)

                        frame = self.apply_zoom_effect(frame, zoom_region, current_zoom_factor)

                    elif zoom_region is not None:
                        if (enable_shake and shake_start_frame and shake_end_frame and 
                            shake_start_frame <= frame_count < shake_end_frame):
                            zoom_region = self.apply_shake_effect(zoom_region, shake_intensity)
                        frame = self.apply_zoom_effect(frame, zoom_region, current_zoom_factor)
                else:
                    if not should_zoom:
                        target_face = None
                        zoom_region = None

                self.out.write(frame)
                frame_count += 1

                if frame_count % 30 == 0:
                    print(f"Processed: {frame_count}/{self.total_frames} frames")

        except Exception as e:
            print(f"âŒ Error while processing video: {e}")
            raise
        finally:
            self.release()

        print("âœ… Video processing completed!")


def create_face_zoom_video(input_video, output_video, zoom_type="instant", **kwargs):
    """
    Create a face-zoom effect video (safe version).
    """
    try:
        with VideoFaceZoom(input_video, output_video) as processor:
            zoom_factor = kwargs.get('zoom_factor', 1.8)
            enable_shake = kwargs.get('enable_shake', False)
            shake_intensity = kwargs.get('shake_intensity', 3)
            shake_start_delay = kwargs.get('shake_start_delay', 0.5)

            if zoom_type == "instant":
                zoom_start_time = kwargs.get('zoom_start_time', 0)
                zoom_duration = kwargs.get('zoom_duration', 2)

                zoom_start_frame = int(zoom_start_time * processor.fps)
                zoom_duration_frames = int(zoom_duration * processor.fps)

                processor.process_video(
                    zoom_start_frame=zoom_start_frame,
                    zoom_duration_frames=zoom_duration_frames,
                    zoom_factor=zoom_factor,
                    zoom_type="instant",
                    enable_shake=enable_shake,
                    shake_intensity=shake_intensity,
                    shake_start_delay=shake_start_delay
                )

            elif zoom_type == "gradual":
                gradual_start_time = kwargs.get('gradual_start_time', 0)
                gradual_end_time = kwargs.get('gradual_end_time', 3)
                hold_duration = kwargs.get('hold_duration', 2)

                gradual_start_frame = int(gradual_start_time * processor.fps)
                gradual_end_frame = int(gradual_end_time * processor.fps)
                gradual_hold_frames = int(hold_duration * processor.fps)

                processor.process_video(
                    zoom_factor=zoom_factor,
                    zoom_type="gradual",
                    gradual_start_frame=gradual_start_frame,
                    gradual_end_frame=gradual_end_frame,
                    gradual_hold_frames=gradual_hold_frames,
                    enable_shake=enable_shake,
                    shake_intensity=shake_intensity,
                    shake_start_delay=shake_start_delay
                )

    except Exception as e:
        print(f"âŒ Error in create_face_zoom_video: {e}")
        raise
