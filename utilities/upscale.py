import os
import torch
from PIL import Image
import sys
import cv2
import numpy as np
# sys.path.append('/workspace/multitalk_verquant/RealESRGAN')
current_dir = os.path.dirname(os.path.abspath(__file__))
realesrgan_path = os.path.join(current_dir, 'RealESRGAN')
sys.path.append(realesrgan_path)

from RealESRGAN import RealESRGAN
import time

def blend_images(original, upscaled, blend_ratio=0.2):
    # Resize áº£nh gá»‘c lÃªn cÃ¹ng kÃ­ch thÆ°á»›c vá»›i áº£nh upscaled
    original_resized = original.resize(upscaled.size, Image.LANCZOS)

    # Convert sang numpy Ä‘á»ƒ xá»­ lÃ½
    orig_np = np.array(original_resized, dtype=np.float32)
    upsc_np = np.array(upscaled, dtype=np.float32)

    # Trá»™n theo tá»· lá»‡
    blended = (1 - blend_ratio) * upsc_np + blend_ratio * orig_np
    blended = np.clip(blended, 0, 255).astype(np.uint8)

    return Image.fromarray(blended)

def apply_sharpening(image, strength=0.3):
    """Ãp dá»¥ng sharpening nháº¹ Ä‘á»ƒ tÄƒng Ä‘á»™ sáº¯c nÃ©t tá»± nhiÃªn"""
    img_np = np.array(image)

    # Gaussian blur
    blurred = cv2.GaussianBlur(img_np, (3, 3), 1.0)

    # Unsharp masking
    sharpened = cv2.addWeighted(img_np, 1 + strength, blurred, -strength, 0)

    return Image.fromarray(np.clip(sharpened, 0, 255).astype(np.uint8))

def upscale_image_enhanced(input_path: str, output_path: str = "results", scale: int = 4,
                          model_type: str = "realesr-general", blend_ratio: float = 0.0,
                          sharpen: bool = False):
    """Upscale má»™t áº£nh Ä‘Æ¡n láº» vá»›i cÃ¡c tÃ¹y chá»n cáº£i tiáº¿n"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = RealESRGAN(device, scale=scale)

    # Chá»n model phÃ¹ há»£p
    if model_type == "realesr-general":
        model_path = f'/content/drive/MyDrive/20_6upscale_video/RealESRGAN-20250620T093117Z-1-001/RealESRGAN/weights/realesr-general-x4v3.pth'
    else:
        model_path = f'RealESRGAN/weights/RealESRGAN_x{scale}.pth'

    model.load_weights(model_path, download=True)

    os.makedirs(output_path, exist_ok=True)
    image_name = os.path.basename(input_path)
    print(f"\nğŸš€ Äang xá»­ lÃ½: {image_name}")
    print(f"ğŸ¨ Model: {model_type}")
    print(f"ğŸ”€ Blend ratio: {blend_ratio}")
    print(f"âœ¨ Sharpening: {'CÃ³' if sharpen else 'KhÃ´ng'}")

    original_image = Image.open(input_path).convert('RGB')

    start = time.time()
    sr_image = model.predict(original_image)

    if blend_ratio > 0:
        sr_image = blend_images(original_image, sr_image, blend_ratio)
        print(f"ğŸ”€ ÄÃ£ Ã¡p dá»¥ng blending vá»›i tá»· lá»‡ {blend_ratio}")

    if sharpen:
        sr_image = apply_sharpening(sr_image)
        print(f"âœ¨ ÄÃ£ Ã¡p dá»¥ng sharpening")

    elapsed = time.time() - start
    save_path = os.path.join(output_path, f"upscaled_{image_name}")
    sr_image.save(save_path)

    print(f"âœ… ÄÃ£ upscale xong áº£nh: {image_name}")
    print(f"â±ï¸ Thá»i gian xá»­ lÃ½: {elapsed:.2f} giÃ¢y")
    print(f"ğŸ’¾ ÄÃ£ lÆ°u áº£nh táº¡i: {save_path}")

    return save_path

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ–¼ï¸ REALESRGAN IMAGE UPSCALER")
    print("=" * 60)

    image_path = input("ğŸ“ Nháº­p Ä‘Æ°á»ng dáº«n áº£nh (hoáº·c Enter Ä‘á»ƒ dÃ¹ng máº·c Ä‘á»‹nh): ").strip()

    if not image_path:
        image_path = "/content/drive/MyDrive/20 6 upscale video/blurimg.png"

    if not os.path.exists(image_path):
        print(f"âŒ File khÃ´ng tá»“n táº¡i: {image_path}")
    else:
        scale_input = input("ğŸ“ Nháº­p scale factor (2, 4, 8) [máº·c Ä‘á»‹nh: 4]: ").strip()
        scale = 4
        if scale_input in ['2', '4', '8']:
            scale = int(scale_input)

        print("\nğŸ¨ Chá»n model:")
        print("1. realesr-general (tá»± nhiÃªn hÆ¡n, Ã­t bá»‹ hoáº¡t hÃ¬nh hÃ³a)")
        print("2. RealESRGAN (sáº¯c nÃ©t hÆ¡n, cÃ³ thá»ƒ bá»‹ hoáº¡t hÃ¬nh hÃ³a)")
        model_choice = input("Lá»±a chá»n (1/2) [máº·c Ä‘á»‹nh: 1]: ").strip()
        model_type = "realesr-general" if model_choice != "2" else "realesrgan"

        blend_input = input("ğŸ”€ Blend ratio (0.0-0.5, cÃ ng cao cÃ ng tá»± nhiÃªn) [máº·c Ä‘á»‹nh: 0.1]: ").strip()
        blend_ratio = 0.1
        try:
            if blend_input:
                blend_ratio = max(0.0, min(0.5, float(blend_input)))
        except ValueError:
            pass

        sharpen_choice = input("âœ¨ Ãp dá»¥ng sharpening? (y/n) [máº·c Ä‘á»‹nh: n]: ").strip().lower()
        sharpen = sharpen_choice == 'y'

        print(f"\nğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ vá»›i cÃ¡c tham sá»‘:")
        print(f"   - Model: {model_type}")
        print(f"   - Scale: x{scale}")
        print(f"   - Blend ratio: {blend_ratio}")
        print(f"   - Sharpening: {'CÃ³' if sharpen else 'KhÃ´ng'}")

        upscale_image_enhanced(image_path, model_type=model_type,
                             blend_ratio=blend_ratio, sharpen=sharpen)