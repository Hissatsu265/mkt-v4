import os
import torch
from PIL import Image
import sys
import cv2
import subprocess
import shutil
import glob
import numpy as np
# sys.path.append('/content/drive/MyDrive/20_6upscale_video/RealESRGAN-20250620T093117Z-1-001/RealESRGAN')
current_dir = os.path.dirname(os.path.abspath(__file__))
realesrgan_path = os.path.join(current_dir, 'RealESRGAN')
sys.path.append(realesrgan_path)
from RealESRGAN import RealESRGAN
import time

def blend_images(original, upscaled, blend_ratio=0.2):
    """Trá»™n áº£nh gá»‘c vá»›i áº£nh upscaled Ä‘á»ƒ giáº£m hiá»‡u á»©ng hoáº¡t hÃ¬nh"""
    # Resize áº£nh gá»‘c lÃªn cÃ¹ng kÃ­ch thÆ°á»›c vá»›i áº£nh upscaled
    original_resized = original.resize(upscaled.size, Image.LANCZOS)

    # Convert sang numpy Ä‘á»ƒ xá»­ lÃ½
    orig_np = np.array(original_resized, dtype=np.float32)
    upsc_np = np.array(upscaled, dtype=np.float32)

    # Trá»™n theo tá»· lá»‡
    blended = (1 - blend_ratio) * upsc_np + blend_ratio * orig_np
    blended = np.clip(blended, 0, 255).astype(np.uint8)

    return Image.fromarray(blended)

def apply_sharpening(image, strength=0.3):
    """Ãp dá»¥ng sharpening nháº¹ Ä‘á»ƒ tÄƒng Ä‘á»™ sáº¯c nÃ©t tá»± nhiÃªn"""
    img_np = np.array(image)

    # Gaussian blur
    blurred = cv2.GaussianBlur(img_np, (3, 3), 1.0)

    # Unsharp masking
    sharpened = cv2.addWeighted(img_np, 1 + strength, blurred, -strength, 0)

    return Image.fromarray(np.clip(sharpened, 0, 255).astype(np.uint8))

def upscale_image_enhanced(input_path: str, output_path: str = "results", scale: int = 4,
                          model_type: str = "realesr-general", blend_ratio: float = 0.0,
                          sharpen: bool = False):
    """Upscale má»™t áº£nh Ä‘Æ¡n láº» vá»›i cÃ¡c tÃ¹y chá»n cáº£i tiáº¿n"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    model = RealESRGAN(device, scale=scale)

    # Chá»n model phÃ¹ há»£p
    if model_type == "realesr-general":
        model_path = f'/content/drive/MyDrive/20_6upscale_video/RealESRGAN-20250620T093117Z-1-001/RealESRGAN/weights/realesr-general-x4v3.pth'
    else:
        model_path = f'/workspace/multitalk_verquant/RealESRGAN/RealESRGAN/weights/RealESRGAN_x2.pth'

    model.load_weights(model_path, download=False)

    os.makedirs(output_path, exist_ok=True)
    image_name = os.path.basename(input_path)
    print(f"\nğŸš€ Äang xá»­ lÃ½: {image_name}")
    print(f"ğŸ¨ Model: {model_type}")
    print(f"ğŸ”€ Blend ratio: {blend_ratio}")
    print(f"âœ¨ Sharpening: {'CÃ³' if sharpen else 'KhÃ´ng'}")

    original_image = Image.open(input_path).convert('RGB')

    start = time.time()
    sr_image = model.predict(original_image)

    if blend_ratio > 0:
        sr_image = blend_images(original_image, sr_image, blend_ratio)
        print(f"ğŸ”€ ÄÃ£ Ã¡p dá»¥ng blending vá»›i tá»· lá»‡ {blend_ratio}")

    if sharpen:
        sr_image = apply_sharpening(sr_image)
        print(f"âœ¨ ÄÃ£ Ã¡p dá»¥ng sharpening")

    elapsed = time.time() - start
    save_path = os.path.join(output_path, f"upscaled_{image_name}")
    sr_image.save(save_path)

    print(f"âœ… ÄÃ£ upscale xong áº£nh: {image_name}")
    print(f"â±ï¸ Thá»i gian xá»­ lÃ½: {elapsed:.2f} giÃ¢y")
    print(f"ğŸ’¾ ÄÃ£ lÆ°u áº£nh táº¡i: {save_path}")

    return save_path

def get_video_info(video_path: str):
    """Láº¥y thÃ´ng tin video (fps, duration, etc.)"""
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    duration = frame_count / fps
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    cap.release()

    return {
        'fps': fps,
        'frame_count': frame_count,
        'duration': duration,
        'width': width,
        'height': height
    }

def extract_frames(video_path: str, output_dir: str):
    """TÃ¡ch video thÃ nh cÃ¡c frame báº±ng ffmpeg"""
    os.makedirs(output_dir, exist_ok=True)

    cmd = [
        'ffmpeg', '-i', video_path,
        '-q:v', '1',
        '-pix_fmt', 'rgb24',
        os.path.join(output_dir, 'frame_%06d.png'),
        '-y'
    ]

    print(f"ğŸ¬ Äang tÃ¡ch video thÃ nh frames...")
    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode != 0:
        print(f"âŒ Lá»—i khi tÃ¡ch frames: {result.stderr}")
        return False

    frame_files = glob.glob(os.path.join(output_dir, 'frame_*.png'))
    print(f"âœ… ÄÃ£ tÃ¡ch Ä‘Æ°á»£c {len(frame_files)} frames")
    return True

def upscale_frames_enhanced(frames_dir: str, output_dir: str, scale: int = 4,
                           model_type: str = "realesr-general", blend_ratio: float = 0.0,
                           sharpen: bool = False):
    """Upscale táº¥t cáº£ cÃ¡c frame vá»›i cÃ¡c tÃ¹y chá»n cáº£i tiáº¿n"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸ–¥ï¸ Sá»­ dá»¥ng device: {device}")
    print(f"ğŸ¨ Model: {model_type}")
    print(f"ğŸ”€ Blend ratio: {blend_ratio}")
    print(f"âœ¨ Sharpening: {'CÃ³' if sharpen else 'KhÃ´ng'}")

    model = RealESRGAN(device, scale=scale)

    if model_type == "realesr-general":
        model_path = f'/content/drive/MyDrive/20_6upscale_video/RealESRGAN-20250620T093117Z-1-001/RealESRGAN/weights/realesr-general-x4v3.pth'
    else:
        model_path = f'/workspace/multitalk_verquant/RealESRGAN/RealESRGAN/weights/RealESRGAN_x2.pth'

    model.load_weights(model_path, download=False)

    os.makedirs(output_dir, exist_ok=True)

    frame_files = sorted(glob.glob(os.path.join(frames_dir, 'frame_*.png')))
    total_frames = len(frame_files)

    if total_frames == 0:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y frame nÃ o Ä‘á»ƒ xá»­ lÃ½!")
        return False

    print(f"ğŸš€ Báº¯t Ä‘áº§u upscale {total_frames} frames...")
    start_time = time.time()

    for i, frame_path in enumerate(frame_files, 1):
        frame_start = time.time()

        original_image = Image.open(frame_path).convert('RGB')
        sr_image = model.predict(original_image)

        # Ãp dá»¥ng cÃ¡c ká»¹ thuáº­t cáº£i tiáº¿n
        if blend_ratio > 0:
            sr_image = blend_images(original_image, sr_image, blend_ratio)

        if sharpen:
            sr_image = apply_sharpening(sr_image)

        frame_name = os.path.basename(frame_path)
        output_path = os.path.join(output_dir, frame_name)
        sr_image.save(output_path)

        frame_elapsed = time.time() - frame_start
        total_elapsed = time.time() - start_time
        avg_time = total_elapsed / i
        eta = avg_time * (total_frames - i)

        print(f"âœ… Frame {i}/{total_frames} - {frame_elapsed:.2f}s - ETA: {eta:.1f}s")

    total_time = time.time() - start_time
    print(f"ğŸ‰ HoÃ n thÃ nh upscale táº¥t cáº£ frames trong {total_time:.2f} giÃ¢y")
    return True

def create_video_from_frames(frames_dir: str, output_video_path: str, fps: float, original_video_path: str = None):
    """GhÃ©p cÃ¡c frame thÃ nh video vÃ  copy audio tá»« video gá»‘c"""

    cmd = [
        'ffmpeg',
        '-framerate', str(fps),
        '-i', os.path.join(frames_dir, 'frame_%06d.png'),
        '-c:v', 'libx264',
        '-pix_fmt', 'yuv420p',
        '-crf', '18',
        '-preset', 'medium',
        output_video_path + '_no_audio.mp4',
        '-y'
    ]

    print(f"ğŸ¬ Äang táº¡o video tá»« frames...")
    result = subprocess.run(cmd, capture_output=True, text=True)

    if result.returncode != 0:
        print(f"âŒ Lá»—i khi táº¡o video: {result.stderr}")
        return False

    if original_video_path and os.path.exists(original_video_path):
        print(f"ğŸ”Š Äang copy audio tá»« video gá»‘c...")
        cmd_audio = [
            'ffmpeg',
            '-i', output_video_path + '_no_audio.mp4',
            '-i', original_video_path,
            '-c:v', 'copy',
            '-c:a', 'aac',
            '-map', '0:v:0',
            '-map', '1:a:0',
            '-shortest',
            output_video_path,
            '-y'
        ]

        result = subprocess.run(cmd_audio, capture_output=True, text=True)

        if result.returncode == 0:
            os.remove(output_video_path + '_no_audio.mp4')
            print(f"âœ… ÄÃ£ thÃªm audio vÃ o video")
        else:
            shutil.move(output_video_path + '_no_audio.mp4', output_video_path)
            print(f"âš ï¸ KhÃ´ng thá»ƒ copy audio, video chá»‰ cÃ³ hÃ¬nh áº£nh")
    else:
        shutil.move(output_video_path + '_no_audio.mp4', output_video_path)

    print(f"âœ… Video Ä‘Ã£ Ä‘Æ°á»£c táº¡o: {output_video_path}")
    return True

def upscale_video_enhanced(video_path: str, output_path: str = None, scale: int = 2,
                          model_type: str = "realesr-general", blend_ratio: float = 0.0,
                          sharpen: bool = False, keep_temp_files: bool = False):
    """Upscale toÃ n bá»™ video vá»›i cÃ¡c tÃ¹y chá»n cáº£i tiáº¿n"""

    if not os.path.exists(video_path):
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file video: {video_path}")
        return

    if output_path is None:
        video_dir = os.path.dirname(video_path)
        video_name = os.path.splitext(os.path.basename(video_path))[0]
        suffix = f"_{model_type}" if model_type != "realesr-general" else ""
        output_path = os.path.join(video_dir, f"{video_name}_upscaled_x{scale}{suffix}.mp4")

    temp_dir = "temp_video_processing"
    frames_dir = os.path.join(temp_dir, "original_frames")
    upscaled_frames_dir = os.path.join(temp_dir, "upscaled_frames")

    try:
        print(f"ğŸ“¹ Äang phÃ¢n tÃ­ch video: {os.path.basename(video_path)}")
        video_info = get_video_info(video_path)
        print(f"ğŸ“Š ThÃ´ng tin video:")
        print(f"   - Äá»™ phÃ¢n giáº£i: {video_info['width']}x{video_info['height']}")
        print(f"   - FPS: {video_info['fps']:.2f}")
        print(f"   - Sá»‘ frame: {video_info['frame_count']}")
        print(f"   - Thá»i lÆ°á»£ng: {video_info['duration']:.2f} giÃ¢y")
        print(f"   - Äá»™ phÃ¢n giáº£i sau upscale: {video_info['width']*scale}x{video_info['height']*scale}")

        if not extract_frames(video_path, frames_dir):
            return

        if not upscale_frames_enhanced(frames_dir, upscaled_frames_dir, scale,
                                      model_type, blend_ratio, sharpen):
            return

        if not create_video_from_frames(upscaled_frames_dir, output_path, video_info['fps'], video_path):
            return

        print(f"\nğŸ‰ HOÃ€N THÃ€NH!")
        print(f"ğŸ“ Video gá»‘c: {video_path}")
        print(f"ğŸ’¾ Video Ä‘Ã£ upscale: {output_path}")
        print(f"ğŸ“ Scale: x{scale}")
        print(f"ğŸ¨ Model: {model_type}")

    except Exception as e:
        print(f"âŒ CÃ³ lá»—i xáº£y ra: {str(e)}")

    finally:
        if not keep_temp_files and os.path.exists(temp_dir):
            print(f"ğŸ§¹ Äang dá»n dáº¹p files táº¡m...")
            shutil.rmtree(temp_dir)
            print(f"âœ… ÄÃ£ xÃ³a files táº¡m")

if __name__ == '__main__':
    print("=" * 60)
    print("ğŸ¥ REALESRGAN VIDEO UPSCALER - ENHANCED VERSION")
    print("=" * 60)

    video_path = input("ğŸ“ Nháº­p Ä‘Æ°á»ng dáº«n video (hoáº·c Enter Ä‘á»ƒ dÃ¹ng máº·c Ä‘á»‹nh): ").strip()

    if not video_path:
        video_path = "/content/drive/MyDrive/20 6 upscale video/single_long_mediumvram_8step.mp4"

    if not os.path.exists(video_path):
        print(f"âŒ File khÃ´ng tá»“n táº¡i: {video_path}")
        print("Báº¡n cÃ³ muá»‘n upscale áº£nh thay tháº¿ khÃ´ng? (y/n)")
        choice = input().strip().lower()
        if choice == 'y':
            image_path = "/content/drive/MyDrive/20 6 upscale video/blurimg.png"

            # TÃ¹y chá»n cho áº£nh
            print("\nğŸ¨ Chá»n model:")
            print("1. realesr-general (tá»± nhiÃªn hÆ¡n, Ã­t hoáº¡t hÃ¬nh)")
            print("2. RealESRGAN (sáº¯c nÃ©t hÆ¡n, cÃ³ thá»ƒ hoáº¡t hÃ¬nh)")
            model_choice = input("Lá»±a chá»n (1/2) [máº·c Ä‘á»‹nh: 1]: ").strip()
            model_type = "realesr-general" if model_choice != "2" else "realesrgan"

            blend_input = input("ğŸ”€ Blend ratio (0.0-0.5, cÃ ng cao cÃ ng tá»± nhiÃªn) [máº·c Ä‘á»‹nh: 0.1]: ").strip()
            blend_ratio = 0.1
            try:
                if blend_input:
                    blend_ratio = max(0.0, min(0.5, float(blend_input)))
            except:
                pass

            sharpen_choice = input("âœ¨ Ãp dá»¥ng sharpening? (y/n) [máº·c Ä‘á»‹nh: n]: ").strip().lower()
            sharpen = sharpen_choice == 'y'

            upscale_image_enhanced(image_path, model_type=model_type,
                                 blend_ratio=blend_ratio, sharpen=sharpen)
    else:
        scale_input = input("ğŸ“ Nháº­p scale factor (2, 4, 8) [máº·c Ä‘á»‹nh: 4]: ").strip()
        scale = 4
        if scale_input in ['2', '4', '8']:
            scale = int(scale_input)

        print("\nğŸ¨ Chá»n model:")
        print("1. realesr-general (tá»± nhiÃªn hÆ¡n, Ã­t bá»‹ hoáº¡t hÃ¬nh hÃ³a)")
        print("2. RealESRGAN (sáº¯c nÃ©t hÆ¡n, cÃ³ thá»ƒ bá»‹ hoáº¡t hÃ¬nh hÃ³a)")
        model_choice = input("Lá»±a chá»n (1/2) [máº·c Ä‘á»‹nh: 1]: ").strip()
        model_type = "realesr-general" if model_choice != "2" else "realesrgan"

        blend_input = input("ğŸ”€ Blend ratio (0.0-0.5, cÃ ng cao cÃ ng tá»± nhiÃªn) [máº·c Ä‘á»‹nh: 0.1]: ").strip()
        blend_ratio = 0.1
        try:
            if blend_input:
                blend_ratio = max(0.0, min(0.5, float(blend_input)))
        except ValueError:
            pass

        sharpen_choice = input("âœ¨ Ãp dá»¥ng sharpening? (y/n) [máº·c Ä‘á»‹nh: n]: ").strip().lower()
        sharpen = sharpen_choice == 'y'

        print(f"\nğŸš€ Báº¯t Ä‘áº§u xá»­ lÃ½ vá»›i cÃ¡c tham sá»‘:")
        print(f"   - Model: {model_type}")
        print(f"   - Scale: x{scale}")
        print(f"   - Blend ratio: {blend_ratio}")
        print(f"   - Sharpening: {'CÃ³' if sharpen else 'KhÃ´ng'}")

        upscale_video_enhanced(video_path, scale=scale, model_type=model_type,
                              blend_ratio=blend_ratio, sharpen=sharpen)